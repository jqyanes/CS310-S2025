{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "bdc32761-27f1-4b41-997f-d397d3c0fde7",
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nfrom pandas import Series\nfrom pandas import DataFrame\nimport csv\nimport re\n\ndf = pd.read_csv(\"covid_19_set_3.csv\")\ndf.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 12,
          "output_type": "execute_result",
          "data": {
            "text/plain": "   ID Province/State Country/Region       Lat       Long        Date  \\\n0   1            NaN    Afghanistan  33.93911  67.709953  2020/01/22   \n1   2            NaN        Albania   41.1533    20.1683  2020/01/22   \n2   3            NaN        Algeria   28.0339     1.6596  2020/01/22   \n3   4            NaN        Andorra   42.5063     1.5218  2020/01/22   \n4   5            NaN         Angola  -11.2027    17.8739  2020/01/22   \n\n  Confirmed Deaths Recovered Active             WHO Region  \n0         0      0         0      0  Eastern Mediterranean  \n1         0      0         0      0                 Europe  \n2         0      0         0      0                 Africa  \n3         0      0         0      0                 Europe  \n4         0      0         0      0                 Africa  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Province/State</th>\n      <th>Country/Region</th>\n      <th>Lat</th>\n      <th>Long</th>\n      <th>Date</th>\n      <th>Confirmed</th>\n      <th>Deaths</th>\n      <th>Recovered</th>\n      <th>Active</th>\n      <th>WHO Region</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>Afghanistan</td>\n      <td>33.93911</td>\n      <td>67.709953</td>\n      <td>2020/01/22</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Eastern Mediterranean</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>NaN</td>\n      <td>Albania</td>\n      <td>41.1533</td>\n      <td>20.1683</td>\n      <td>2020/01/22</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Europe</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>Algeria</td>\n      <td>28.0339</td>\n      <td>1.6596</td>\n      <td>2020/01/22</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Africa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>Andorra</td>\n      <td>42.5063</td>\n      <td>1.5218</td>\n      <td>2020/01/22</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Europe</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>Angola</td>\n      <td>-11.2027</td>\n      <td>17.8739</td>\n      <td>2020/01/22</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Africa</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12
    },
    {
      "id": "edcc4981-61ad-4155-84e3-f6c782eb7bde",
      "cell_type": "code",
      "source": "#Null entries\n\ndf.info() #polluted columns have 1000 null values each\n\n#getting all rows polluted with null values\nany_null = df[df.iloc[:, 2:].isnull().any(axis=1)] \nany_null #1000 rows, shows all rows with nulls are completely blank",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 49068 entries, 0 to 49067\nData columns (total 11 columns):\n #   Column          Non-Null Count  Dtype \n---  ------          --------------  ----- \n 0   ID              49068 non-null  int64 \n 1   Province/State  14375 non-null  object\n 2   Country/Region  48068 non-null  object\n 3   Lat             48068 non-null  object\n 4   Long            48068 non-null  object\n 5   Date            48068 non-null  object\n 6   Confirmed       48068 non-null  object\n 7   Deaths          48068 non-null  object\n 8   Recovered       48068 non-null  object\n 9   Active          48068 non-null  object\n 10  WHO Region      48068 non-null  object\ndtypes: int64(1), object(10)\nmemory usage: 2.2+ MB\n"
        },
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "          ID Province/State Country/Region  Lat Long Date Confirmed Deaths  \\\n41        42            NaN            NaN  NaN  NaN  NaN       NaN    NaN   \n52        53            NaN            NaN  NaN  NaN  NaN       NaN    NaN   \n102      103            NaN            NaN  NaN  NaN  NaN       NaN    NaN   \n113      114            NaN            NaN  NaN  NaN  NaN       NaN    NaN   \n179      180            NaN            NaN  NaN  NaN  NaN       NaN    NaN   \n...      ...            ...            ...  ...  ...  ...       ...    ...   \n48829  48830            NaN            NaN  NaN  NaN  NaN       NaN    NaN   \n48838  48839            NaN            NaN  NaN  NaN  NaN       NaN    NaN   \n48974  48975            NaN            NaN  NaN  NaN  NaN       NaN    NaN   \n49010  49011            NaN            NaN  NaN  NaN  NaN       NaN    NaN   \n49024  49025            NaN            NaN  NaN  NaN  NaN       NaN    NaN   \n\n      Recovered Active WHO Region  \n41          NaN    NaN        NaN  \n52          NaN    NaN        NaN  \n102         NaN    NaN        NaN  \n113         NaN    NaN        NaN  \n179         NaN    NaN        NaN  \n...         ...    ...        ...  \n48829       NaN    NaN        NaN  \n48838       NaN    NaN        NaN  \n48974       NaN    NaN        NaN  \n49010       NaN    NaN        NaN  \n49024       NaN    NaN        NaN  \n\n[1000 rows x 11 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Province/State</th>\n      <th>Country/Region</th>\n      <th>Lat</th>\n      <th>Long</th>\n      <th>Date</th>\n      <th>Confirmed</th>\n      <th>Deaths</th>\n      <th>Recovered</th>\n      <th>Active</th>\n      <th>WHO Region</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>41</th>\n      <td>42</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>53</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>102</th>\n      <td>103</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>113</th>\n      <td>114</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>179</th>\n      <td>180</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>48829</th>\n      <td>48830</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>48838</th>\n      <td>48839</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>48974</th>\n      <td>48975</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>49010</th>\n      <td>49011</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>49024</th>\n      <td>49025</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 11 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13
    },
    {
      "id": "f44005bc-e43c-4ba6-b698-c9362aeff8b0",
      "cell_type": "code",
      "source": "#Typos/outliers (Country/Region, WHO Region)\n\ncr_counts = df['Country/Region'].value_counts()\nprint(cr_counts[cr_counts < 173]) #Country/Region values with a count < 172 are typos/outliers\nwr_counts = df['WHO Region'].value_counts()\nprint(wr_counts[wr_counts < 2000]) #WHO Region values with a count < 1799 are typos/outliers\n\n#getting polluted rows\npolluted_cr_vals = cr_counts[cr_counts < 172].index\npolluted_wr_vals = wr_counts[wr_counts < 1799].index\npolluted_cr = df[df['Country/Region'].isin(polluted_cr_vals)]\npolluted_wr = df[df['WHO Region'].isin(polluted_wr_vals)]",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Country/Region\nArmenia          172\nCh ina            17\nChnia             16\nChi na            13\nCina              13\n                ... \nNetherland         1\nAlbnaia            1\nIcel and           1\napan               1\nUited Kingdom      1\nName: count, Length: 753, dtype: int64\nWHO Region\nSouth-East Asia           1799\nEuorpe                      27\nEruope                      24\nEurpoe                      23\nEuroe                       23\n                          ... \nEastern Mediterranan         1\nEast ern Mediterranean       1\nEastern eMditerranean        1\nEastern Meditreranean        1\nEastern Me diterranean       1\nName: count, Length: 166, dtype: int64\n"
        }
      ],
      "execution_count": 14
    },
    {
      "id": "2e75c65a-b617-4357-8748-dceccccbfb05",
      "cell_type": "code",
      "source": "#Wrong format (Date)\n\n#checking year range\nprint(len(df[~df['Date'].str.match(r'^\\s*2020\\s*\\S*\\s*$', na = True)])) #dates outside of year 2020 are outliers\n\n#getting polluted rows (entry is either not in yyyy/mm/dd format, not a real date, or not from year 2020)\npolluted_da = df[~df['Date'].str.match(r'^\\s*2020/(0[1-9]|1[0-2])/(0[1-9]|[1-2][0-9]|3[0-1])\\s*$', na = True)]\n\n#checking for not real dates not caught by above regex\nprint(len(df[df['Date'].str.match(r'^\\s*2020/02/3[0-1]\\s*$', na = False)])) \nprint(len(df[df['Date'].str.match(r'^\\s*2020/0(4|6|9)/31\\s*$', na = False)]))\nprint(len(df[df['Date'].str.match(r'^\\s*2020/11/31\\s*$', na = False)]))",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "431\n0\n0\n0\n"
        }
      ],
      "execution_count": 15
    },
    {
      "id": "a56bd832-5902-4438-b978-2f0a0d997b83",
      "cell_type": "code",
      "source": "#(Confirmed, Deaths, Recovered, Active)\n\n#Value is not a non-negative integer\npolluted_c = df[~df['Confirmed'].astype(\"string\").str.isdecimal()]\npolluted_de = df[~df['Deaths'].astype(\"string\").str.isdecimal()]\npolluted_r = df[~df['Recovered'].astype(\"string\").str.isdecimal()]\npolluted_a = df[~df['Active'].astype(\"string\").str.isdecimal()]\n\n#Values are non-negative integers, but Active != Confirmed - Deaths - Recovered\n#Note: will be listed as pollution in the 'Active' column\ncdera_nnints = df[df['Active'].astype(\"string\").str.isdecimal() & df['Confirmed'].astype(\"string\").str.isdecimal() & df['Deaths'].astype(\"string\").str.isdecimal() & df['Recovered'].astype(\"string\").str.isdecimal()]\npolluted_a2 = df[df['ID'].isin(cdera_nnints['ID']) & (pd.to_numeric(df['Active'], errors='coerce') != pd.to_numeric(df['Confirmed'], errors='coerce') - pd.to_numeric(df['Deaths'], errors='coerce') - pd.to_numeric(df['Recovered'], errors='coerce'))]\n\n#Outliers \n#ISSUE: might disproportionately affect entries from regions with large populations\n#getting rows with non-negative ints for each column\nc_nnints = df[df['Confirmed'].astype(\"string\").str.isdecimal()]\nde_nnints = df[df['Deaths'].astype(\"string\").str.isdecimal()]\nr_nnints = df[df['Recovered'].astype(\"string\").str.isdecimal()]\na_nnints = df[df['Active'].astype(\"string\").str.isdecimal()]\n\n#finding outliers (value is <= Q1 - 1.5IQR or >= Q3 + 1.5IQR)\n#note: only looks at rows with non-negative ints, so no need to specify that lower bound should be >= 0\nc_q1 = c_nnints['Confirmed'].astype(int).quantile(0.25)\nc_q3 = c_nnints['Confirmed'].astype(int).quantile(0.75)\nc_iqr = c_q3 - c_q1\nprint('Confirmed: Outlier if <=', c_q1 - 1.5*c_iqr, 'or >=', c_q3 + 1.5*c_iqr)\nc_outliers = c_nnints[(c_nnints['Confirmed'].astype(int) <= (c_q1 - 1.5*c_iqr)) | (c_nnints['Confirmed'].astype(int) >= (c_q3 + 1.5*c_iqr))]\nprint(len(c_outliers))\n\nde_q1 = de_nnints['Deaths'].astype(int).quantile(0.25)\nde_q3 = de_nnints['Deaths'].astype(int).quantile(0.75)\nde_iqr = de_q3 - de_q1\nprint('Deaths: Outlier if <=', de_q1 - 1.5*de_iqr, 'or >=', de_q3 + 1.5*de_iqr)\nde_outliers = de_nnints[(de_nnints['Deaths'].astype(int) <= (de_q1 - 1.5*de_iqr)) | (de_nnints['Deaths'].astype(int) >= (de_q3 + 1.5*de_iqr))]\nprint(len(de_outliers))\n\nr_q1 = r_nnints['Recovered'].astype(int).quantile(0.25)\nr_q3 = r_nnints['Recovered'].astype(int).quantile(0.75)\nr_iqr = r_q3 - r_q1\nprint('Recovered: Outlier if <=', r_q1 - 1.5*r_iqr, 'or >=', r_q3 + 1.5*r_iqr)\nr_outliers = r_nnints[(r_nnints['Recovered'].astype(int) <= (r_q1 - 1.5*r_iqr)) | (r_nnints['Recovered'].astype(int) >= (r_q3 + 1.5*r_iqr))]\nprint(len(r_outliers))\n\na_q1 = a_nnints['Active'].astype(int).quantile(0.25)\na_q3 = a_nnints['Active'].astype(int).quantile(0.75)\na_iqr = a_q3 - a_q1\nprint('Active: Outlier if <=', a_q1 - 1.5*a_iqr, 'or >=', a_q3 + 1.5*a_iqr)\na_outliers = a_nnints[(a_nnints['Active'].astype(int) <= (a_q1 - 1.5*a_iqr)) | (a_nnints['Active'].astype(int) >= (a_q3 + 1.5*a_iqr))]\n#remove rows where Active != Confirmed - Deaths - Recovered (already accounted for)\na_outliers = a_outliers[~a_outliers['ID'].isin(polluted_a2['ID'])]\nprint(len(a_outliers))\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Confirmed: Outlier if <= -2298.5 or >= 3841.5\n8511\nDeaths: Outlier if <= -48.0 or >= 80.0\n8733\nRecovered: Outlier if <= -1059.0 or >= 1765.0\n7707\nActive: Outlier if <= -937.5 or >= 1562.5\n8351\n"
        }
      ],
      "execution_count": 16
    },
    {
      "id": "8f62ff2a-b030-480f-a045-73cbff7e73d0",
      "cell_type": "code",
      "source": "#(Lat, Long)\n\n#Not a number \n#Not in valid range (-90 to 90 for lat, -180 to 180 for long)\n#Not 4 decimal places (as most entries seem to have that amount)\npolluted_la = df[~df['Lat'].str.match(r'^\\s*-?([1-8]?[0-9]|90).\\d{4}\\s*$', na = True)]\npolluted_lo = df[~df['Long'].str.match(r'^\\s*-?([1-9]?[0-9]|1[0-7][0-9]|180).\\d{4}\\s*$', na = True)]\n\n#ISSUE: 4 decimal place requirement might be too strict?\nprint(len(polluted_la))\nprint(len(polluted_lo))",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "15919\n15752\n"
        }
      ],
      "execution_count": 17
    },
    {
      "id": "7d8fc03f-8a26-4805-9cf5-7331e8acccaf",
      "cell_type": "code",
      "source": "with open('jqy2_polluted_set_3.csv', 'w', newline = '') as newcsvfile:\n    writer = csv.writer(newcsvfile)\n    writer.writerow(['ID', 'Column Name', 'Justification'])\n    for row in any_null['ID']:\n        writer.writerow([row, '', 'Null (entire row)']) \n    for row in polluted_cr['ID']:\n        writer.writerow([row, 'Country/Region', 'Typo or outlier'])\n    for row in polluted_wr['ID']:\n        writer.writerow([row, 'WHO Region', 'Typo or outlier'])\n    for row in polluted_da['ID']:\n        writer.writerow([row, 'Date', 'Not yyyy/mm/dd, fake date, or year != 2020 (outlier)'])\n    for row in polluted_c['ID']:\n        writer.writerow([row, 'Confirmed', 'Not a non-negative int'])\n    for row in polluted_de['ID']:\n        writer.writerow([row, 'Deaths', 'Not a non-negative int'])\n    for row in polluted_r['ID']:\n        writer.writerow([row, 'Recovered', 'Not a non-negative int'])\n    for row in polluted_a['ID']:\n        writer.writerow([row, 'Active', 'Not a non-negative int'])\n    for row in polluted_a2['ID']:\n        writer.writerow([row, 'Active', '!= Confirmed - Deaths - Recovered'])\n    for row in c_outliers['ID']:\n        writer.writerow([row, 'Confirmed', 'Outlier (IQR method)'])\n    for row in de_outliers['ID']:\n        writer.writerow([row, 'Deaths', 'Outlier (IQR method)'])\n    for row in r_outliers['ID']:\n        writer.writerow([row, 'Recovered', 'Outlier (IQR method)'])\n    for row in a_outliers['ID']:\n        writer.writerow([row, 'Active', 'Outlier (IQR method)'])\n    for row in polluted_la['ID']:\n        writer.writerow([row, 'Lat', 'Not number from -90 to 90 with 4 decimal places'])\n    for row in polluted_lo['ID']:\n        writer.writerow([row, 'Long', 'Not number from -180 to 180 with 4 decimal places'])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 18
    }
  ]
}